---
title: "troutr"
author: "Nathan Hoteling"
date: "1/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rvest)
library(dplyr)
library(tidyr)
library(stringr)
library(stringdist)
library(osmdata)
library(ggplot2)

library(kableExtra)

library(textreuse)

source("R/utils.R")
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
va <- sf::st_read("data/gis/cb_2019_us_state_20m/cb_2019_us_state_20m.shp", quiet=TRUE) %>% 
  filter(NAME=="Virginia") %>%
  sf::st_transform(4326)

vaco1 <- sf::st_read("data/gis/cb_2019_us_county_20m/cb_2019_us_county_20m.shp", quiet=TRUE) %>%
  filter(STATEFP == "51") %>%
  sf::st_transform(4326)

# combine City/County with same name, to avoid confusion
vaco2 <- vaco1 %>% group_by(NAME) %>% summarise(geometry = sf::st_union(geometry))

df.trout <- readRDS("data/rds/dftrout.rds")

df.trt <- df.trout %>% 
  dplyr::select(waterbody1, waterbody2, Category, specialtype, county) %>%
  distinct() %>%
  mutate(id = sprintf("trt-%03d", row_number()))    #paste0("trt-",row_number()))
```


<hr>
<br>


# Finding Trout-Water Locations

Water bodies that are included in the Virginia Department of Wildlife Recreation (VDWR) trout stocking program can be browsed on an [interactive map](https://dgif-virginia.maps.arcgis.com/apps/webappviewer/index.html?id=441ed456c8664166bb735b1db6024e48), however there doesn't appear to be a simple way for the average user to download the location data.  For this reason, we explore some methods for determining these locations in the sections below.

<br>

## Brute Force Method

The no-tech solution to this problem is to simply brute-force our way through the trout water locations by manually searching for each individual location.  It's frustrating to know that the locations are definitely recorded in a database somewhere, just not easily accessible to me personally, so I literally pasted each "trout water" into the search bar on the interactive map, navigated to the appropriate search result, dropped a pin on the location, and copied the relevant coordinates.  

As painful as this was, it was manageable (it took about 3-ish hours), and very illuminating.  For example, I found a handful of inconsistencies like misspellings, alternative names, or missing waterways.  In some cases I resorted to a manual google-maps search to help narrow the field and made a judgement call as to the probable location of some waterway.  In all cases I entered a discrete point, even though many of the locations are rivers and streams and trout stocking is probably carried out at a variety of locations along the waterway.  In one case I wasn't able to find the location at all because the name, "Forest Service Office Youth Ponds" was very much ambiguous and I couldn't find where the Forest Service Office is located (apparently even Google doesn't know!); in that case I used the center of the respective county. 

<br>

## VDEQ Data

```{r, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
# First, download these files from:
# https://geohub-vadeq.hub.arcgis.com/pages/Water%20Datasets
# Then read them with sf
#df.rvr <- sf::st_read("data/gis/Rivers_(2020_Final_WQA_IR_Assessment)/Rivers_(2020_Final_WQA_IR_Assessment).shp", quiet=TRUE)
#df.res <- sf::st_read("data/gis/Reservoirs_(2020_Final_WQA_IR_Assessment)/Reservoirs_(2020_Final_WQA_IR_Assessment).shp", quiet=TRUE)
df.rvr <- sf::st_read("data/gis/Trout_Waters_(WQS_Streams___Rivers)/Trout_Waters_(WQS_Streams___Rivers).shp", quiet=TRUE)
df.res <- sf::st_read("data/gis/Trout_Waters_(WQS_Lakes___Reservoirs)/Trout_Waters_(WQS_Lakes___Reservoirs).shp", quiet=TRUE)

epsg_code <- spaceheater::get_epsg(df.rvr$geometry)
EPSG_WGS84 <- spaceheater::epsg_wgs84()

find_county <- function(crd) {
  vv <- sf::st_intersects(crd, vaco1$geometry) %>% unlist()
  nm <- ifelse(length(vv) > 0, vaco1$NAME[vv], NA)
  return(nm)
}


# Combine Rivers & Streams with Lakes & Reservoirs
df.deq <- bind_rows(
  # Rivers & Streams
  df.rvr %>%
    mutate(coord = geometry %>% sf::st_transform(epsg_code) %>% sf::st_centroid() %>% sf::st_transform(EPSG_WGS84),
           src = "rvr") %>%
    as_tibble() %>%
    dplyr::select(GNIS_ID, GNIS_NAME, WATER_NAME, WQS_ID, SHAPE_Leng, src, coord),
  # Lakes & Reservoirs
  df.res %>% 
    mutate(coord = geometry %>% sf::st_transform(epsg_code) %>% sf::st_centroid() %>% sf::st_transform(EPSG_WGS84),
           src = "res") %>%
    as_tibble() %>%
    dplyr::select(GNIS_ID, GNIS_NAME, WATER_NAME, WQS_ID, SHAPE_Leng, src, coord),
) %>%
  mutate(county = purrr::map_chr(coord, find_county))


# Note: some of the coordinates are outside of the state because
# of how the crds are derived above.  Note also that this could, in 
# some rare cases, mean that the county is also incorrect?
df.sub <- df.deq %>% 
  filter(is.na(county)) %>%
  mutate(coord2 = coord %>% 
           sf::st_transform(epsg_code) %>% 
           sf::st_buffer(dist=5000) %>% 
           sf::st_transform(EPSG_WGS84),
         county2 = purrr::map_chr(coord2,find_county))


df.deqx <- df.deq %>% 
  left_join(df.sub %>% dplyr::select(WQS_ID, county2), by=c("WQS_ID")) %>%
  mutate(county = ifelse(is.na(county), county2, county)) %>%
  dplyr::select(-county2)


# Save files
saveRDS(df.deqx, "data/rds/df_deq_v02.rds")
readr::write_csv(df.deqx, "data/csv/df_deq_v02.csv")

saveRDS(df.rvr, "data/rds/df_rvr_v02.rds")
saveRDS(df.res, "data/rds/df_res_v02.rds")
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
#df.rvr <- sf::st_read("data/gis/Rivers_(2020_Final_WQA_IR_Assessment)/Rivers_(2020_Final_WQA_IR_Assessment).shp", quiet=TRUE)
#df.res <- sf::st_read("data/gis/Reservoirs_(2020_Final_WQA_IR_Assessment)/Reservoirs_(2020_Final_WQA_IR_Assessment).shp", quiet=TRUE)

df.rvr <- readRDS("data/rds/df_rvr_v02.rds")
df.res <- readRDS("data/rds/df_res_v02.rds")
df.deq <- readRDS("data/rds/df_deq_v02.rds")
```



The Virginia Department of Environmental Quality (VDEQ) maintains an up-to-date [collection of datasets](https://geohub-vadeq.hub.arcgis.com/pages/Water%20Datasets) related to rivers/streams, and lakes/reservoirs, plus a variety of other features.  In fact, they even have data containing trout rivers/streams and trout lakes/reservoirs.  Combining the rivers/streams and lakes/reservoirs data yields `r unique(df.deq$WQS_ID) %>% length() %>% format(big.mark=",")` unique bodies of water, or `r unique(df.deq$WATER_NAME) %>% length() %>% format(big.mark=",")` _uniquely named_ bodies of water.  There are a couple of reasons for this.  First, the most common name by a significant margin is "Unnamed tributary", with `r df.deq %>% filter(WATER_NAME=="Unnamed tributary") %>% nrow() %>% format(big.mark=",")` occurrences.  To understand this one must consider that there are actually two separate fields with waterbody names.  According to the [data dictionary](https://apps.deq.virginia.gov/mapper_ext/DataFactSheets/Water_Watersheds/DEQFactSheetV1_WQSrivers.pdf) provided by VDEQ the first, "GNIS_NAME" refers to the "Geographic Names Information System waterbody name" and the second, "WATER_NAME" is the name "generally used by DEQ that the feature is associated with".  Looking at the data more closely it appears that the former is a primary waterway and the latter is a more precise name assigned to a tributary or other subsection of the waterbody.

Another reason for the discrepancy between the number of waterbodies and the number of unique names is that many of the bodies of water are divided into multiple segments and some are frequently-used names.  For example, the James River has `r df.deq %>% filter(WATER_NAME=="James River") %>% nrow()` sections outlined in the VDEQ data, and Mill Creek has `r df.deq %>% filter(WATER_NAME=="Mill Creek") %>% nrow()`.  If we look at the geographic distribution of the respective points, the difference becomes clear,

```{r, echo=FALSE, out.width="60%", fig.align="center"}
p <- df.deq %>% 
  filter(WATER_NAME %in% c("James River", "Mill Creek")) %>% 
  ggplot() + 
  geom_sf(data=vaco1, mapping=aes(geometry=geometry), size=0.2, fill="grey95", color="grey65") +
  geom_sf(aes(geometry=coord, color=WATER_NAME)) + 
  scale_color_discrete(name="Water Name") +
  theme_void() +
  theme(legend.position = c(0.2, 0.8))


```

In the plot above one can see that "Mill Creek", being dispersed throughout the trout water region of the state, is simply a common name.  On the other hand, "James River" is a major body of water, so the locations are more tightly packed.  In reality, there are quite a few additional entries for the James River, but they are assigned more precise names associated with sections and tributaries.  To some degree these multiplicity issues can be resolved by filtering the data by county (whereas counties aren't explicitly listed in the VDEQ data, we derive these from shapes available from the [Census Bureau](https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html)).  


### Pairwise comparisons

Comparing water bodies between these two datasets is nontrivial.  As noted in the section above describing the brute-force approach, there are several cases where misspellings, alternative spellings, ambiguous names, or missing data come into play.  Add to this the multiplicities highlighted above for the VDEQ data.  With all of this in mind, the strategy here will be to formulate a set of logical rules that will help us come up with a "best guess" as to which trout waters denoted in the VDWR data correspond to which water bodies in the VDEQ data.  The initial procedure will look like this,

<ol>
  <li>Filter by county</li>
  <li>Determine name similarity</li>
  <li>Filter by jaccard distance</li>
</ol>

<details>
<summary style="font-size:15px">CODE</summary>
```{r, message=FALSE, warning=FALSE}
#
# Pairwise comparisons
#
t0 <- Sys.time()


d <- lapply(1:nrow(df.trt), function(i) {
  df.deq %>% 
    filter(county == df.trt$county[i]) %>%
    mutate(waterbody1 = df.trt$waterbody1[i],
           #jw = stringdist::stringdist(waterbody1, WATER_NAME, method="jw"),
           jc = stringdist::stringdist(waterbody1, WATER_NAME, method="jaccard",q=3),
           id = df.trt$id[i]) %>%
    filter(jc<0.50) %>%
    arrange(id, jc) %>%
    dplyr::select(id, waterbody1, WQS_ID, WATER_NAME, county, jc, src, coord)
})


df.cnd1 <- do.call(rbind, d)
t1 <- Sys.time()
DT_PR <- t1-t0
```
</details>
<br>

The result is a list of candidate pairs that will be used later in the <b>Adjudication</b> step.  In the table below, a Jaccard score of zero means the names are identical.  Some things worth noting here, which will be discussed in greater depth later, 1) some cases return a single result with exact string match, 2) some cases return multiple results with exact string matches, 3) some cases return a mixture of exact and inexact string matches 4) some cases return only inexact string matches, and 5) some trout waters do not return any candidate pairs.  The adjudication step will need to account for each of these scenarios.  Some of these scenarios are evident in the sample printed below,

```{r, echo=FALSE}
df.cnd1 %>%
  dplyr::select(id, waterbody1, WATER_NAME, jc) %>%
  head(n=10) %>%
  kbl(col.names=c("id","Trout Water", "VDEQ water", "Jaccard"), digits=2) %>%
  kable_styling(full_width=FALSE) %>%
  kable_paper()
```

<br>


<br>

### Adjudication

The candidate pairs identified above ideally represent the same waterways present in both datasets, however the reality is more complicated and nuanced.  For example, as was briefly mentioned above, there are five possible outcomes for each candidate pair,

<ol>
  <li>Single exact match</li>
  <li>Multiple exact matches</li>
  <li>Mixture of exact and inexact matches</li>
  <li>Inexact matches</li>
  <li>No candidates</li>
</ol>

During the adjudication process the goal will be to assign a likelihood value to each proposed candidate pair that will account for each of these scenarios.  To do this, we will use Bayes Law,

$$
Pr(\theta | y) = \frac{Pr(y | \theta) Pr(\theta)}{Pr(y)}
$$
where,

<ul>
  <li>$Pr(\theta | y)$ is the probability that the candidate pair is correct, given similarity score $y$ </li>
  <li>$Pr(y | \theta)$ is the probability of similarity score $y$, given the candidate pair is correct </li>
  <li>$Pr(\theta)$ is the prior probability, or the probability that the candidate pair is correct </li>
  <li>$Pr(y)$ is the probability of similarity score $y$</li>
</ul>

The value for $Pr(y | \theta)$ would nominally be determined from data.  For example, if a subset of the candidate pairs were adjudicated manually or otherwise known _a priori_, this information could be used to derive an expression for the probability of similarity score $y$, given a correct candidate pair.  Technically, this information is available in the present case since the brute-force method was carried out above.  However, this is not a typical scenario, so we will use this as a comparative method only.  If no information is available then we will need to come up with a "best guess" as to the relationship.  With this in mind, we assume that the likelihood drops off exponentially as a function of the similarity score, with the probability at $sim=0.1$ exactly half that of $sim=0.0$, and $sim=0.2$ half that of $sim=0.1$, and so on.  In other words, we assume the relation, $P = e^{-\lambda x}$, where $\lambda = \frac{ln(2)}{t_{1/2}}$ and $t_{1/2} = 0.1$,
 
 
```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width="50%", fig.align="center"}
xs <- seq(0, 0.5, by=0.01)
fctn <- function(x,T=0.1) {exp(-(log(2)/T)*x)}
data.frame(x=xs, y=fctn(xs)) %>%
  ggplot() +
  geom_line(aes(x=x,y=y)) +
  labs(x="Jaccard Similarity", y="Likelihood of a correct match") +
  theme_minimal()

```

The value for $Pr(\theta)$ is the prior probability that the candidate pair is correct.  This depends on the number of candidate pairs, plus the possibility that _none_ of the candidate pairs are correct.  Assuming a uniform distribution, we use $\frac{1}{n+1}$, where $n$ is the number of candidate pairs.

The normalization factor can be expanded to, 

$$
Pr(y) = \sum_{\theta}{Pr(\theta) Pr(y | \theta)}
$$
This will be evaluated for each candidate pair determined for a given trout water, plus the possibility that none of the candidates are correct.  Since there is no information as to the probability that none of the candidate pairs is correct, we are forced to come up with a "best guess".  Considering that the VDEQ dataset is supposed to be comprehensive, the likelihood that a given trout waterway is not present is likely very small.  However, there is also the possibility that the waterway is present, but the name is sufficiently different that it is not offered as a candidate pair.  Given these factors, we estimate that there is a 2% likelihood that the waterway is not represented as a candidate pair.

<details>
<summary style="font-size:15px">CODE</summary>
```{r, message=FALSE, warning=FALSE}
# Add the possibility that none of the candidate pairs is correct
faker_frame <- function(n) {
  data.frame(WATER_NAME = "None",
             P_cn = 0.02,
             P_pr = 1/(n+1))
}

# Calculate Prob with Bayes Law
bsn <- function(df) {
  df %>%
    mutate(P_cn = fctn(jc),
           P_pr = 1/(nrow(df)+1)) %>%
    bind_rows(faker_frame(nrow(df))) %>%
    mutate(P_yy = sum(P_cn*P_pr),
           P = P_cn*P_pr/P_yy)
}

# Pairwise data
df.adj1 <- df.cnd1 %>% 
  tidyr::nest(data=c(WQS_ID, WATER_NAME, src,coord, jc)) %>%
  mutate(data = purrr::map(data,bsn)) %>%
  tidyr::unnest(cols=c(data))

```
</details>
<br>

Combining all of this into Bayes Law gives normalized probability values for each candidate pair, plus an additional option that none are correct, 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
df.adj1 %>%
  dplyr::select(id, waterbody1, WATER_NAME, jc, P) %>%
  head(n=10) %>%
  kbl(col.names=c("id","Trout Water", "VDEQ water", "Jaccard", "Probability"), digits=2) %>%
  kable_styling(full_width=FALSE) %>%
  kable_paper()
```

Something isn't quite right with this table.  The results for "Spring Run" are reasonable, where the two exact matches are each assigned 45% probability of being a correct match, the inexact matches are assigned significantly smaller values, and the "None" option even smaller.  This is reasonable.  However, notice that the results for "German River" in which the strings show an exact match, are assigned only a 1% chance of being correct.  The reason for this is that there are `r df.adj1 %>% filter(id=="trt-005") %>% nrow()-1` candidate pairs for this waterway, and all of them are exact string matches.

This raises an interesting question as to how one should use the results here to make an assignment.  In this case, it's worth taking a step back and considering that these waterways are, in all likelihood, sections of the same waterway, and for our purposes we can treat them as such.

<details>
<summary style="font-size:15px">CODE</summary>
```{r, message=FALSE, warning=FALSE}
# filter to just max prob
maxonly <- function(df) {df %>% filter(P == max(P))}
make_line <- function(lonlat) { lonlat %>% as.matrix() %>% sf::st_linestring() }


df.mx1 <- df.adj1 %>%
  dplyr::select(id, waterbody1,WQS_ID, WATER_NAME, src,coord, jc,P) %>%
  tidyr::nest(data=c(WQS_ID, WATER_NAME, src,coord, jc,P)) %>%
  mutate(data = purrr::map(data, maxonly),
         len  = purrr::map_int(data,nrow)) %>%
  #filter(len>1) %>%
  tidyr::unnest(cols=c(data)) 

df.mx <- df.mx1 %>% 
  group_by(id, waterbody1, WATER_NAME) %>%
  summarise(P=sum(P),
            jc=mean(jc))

df.mx2 <- df.mx1 %>%
  filter(len>1) %>%
  group_by(id) %>%
  summarise(m = sf::st_coordinates(coord)) %>% 
  arrange(id,m) %>%
  tidyr::nest() %>%              
  mutate(ln = purrr::map(data, make_line) %>% sf::st_sfc()) 
```
</details>
<br>

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width="60%"}  
df.rv <- df.rvr %>%
  mutate(geometry=geometry %>% sf::st_transform(4326)) %>%
  filter(WQS_ID %in% df.mx1$WQS_ID)

p <- df.mx2 %>%
  ggplot() +
  geom_sf(data=vaco1, mapping=aes(geometry=geometry), size=0.2, fill="grey95", color="grey65") +
  geom_sf(data=df.rv, mapping=aes(geometry=geometry), color="#74a9cf", size=0.5) +
  geom_sf(aes(geometry=ln), size=0.2, color="grey20", alpha=0.7) +
  theme_void()
```








A close inspection of the sample results listed in the table above doesn't reveal anything overly surprising.  For example, in the case of "Irish Creek" there were two exact string matches and each are assigned approximately a 50% chance of being correct, with a very small probability that none are correct. The results for "South Fork Holston River" are truncated in the table above, but there were 13 candidate pairs, 3 of which are exact string matches.  The model gives a 68% chance that one of these exact matches are correct, and a 32% chance that one of the ten other candidate pairs are correct (plus a tiny chance that none are correct).

<br>





At the start of the last section we outlined five possible scenarios for candidate pairs.  The Bayesian model approach gives us the tools to address most of these scenarios, but there is still work to do.  For example, what to do about high multiplicity cases where there are multiple exact matches and what to do about cases where there are no candidate pairs at all?

For multiplicity cases, it may be useful to take a step back and consider that these waterways may, in fact, be the exact same water body.  Recall the example above where the James River, which stretches across the state, is separated into 41 sections in the VDEQ data.  The results considered here are already filtered by county, and there is no guarantee that the trout stocking program divides waterway segments in the same way.  To illustrate this, we take all of the high-multiplicity cases, assume they are each sections of the same waterway, and effectively connect the dots between them.  We compare this to the true path of the waterway from the VDEQ data,

<details>
<summary style="font-size:15px">CODE</summary>
```{r, message=FALSE, warning=FALSE}
# filter to just max prob
maxonly <- function(df) {df %>% filter(P == max(P))}
make_line <- function(lonlat) { lonlat %>% as.matrix() %>% sf::st_linestring() }


df.mx1 <- df.adj1 %>%
  dplyr::select(id, waterbody1,ID305B, WATER_NAME, source,coord, jc,P) %>%
  tidyr::nest(data=c(ID305B, WATER_NAME, source,coord, jc,P)) %>%
  mutate(data = purrr::map(data, maxonly),
         len  = purrr::map_int(data,nrow)) %>%
  tidyr::unnest(cols=c(data)) 

df.mx2 <- df.mx1 %>%
  filter(len>1) %>%
  group_by(id) %>%
  summarise(m = sf::st_coordinates(coord)) %>% 
  arrange(id,m) %>%
  tidyr::nest() %>%              
  mutate(ln = purrr::map(data, make_line) %>% sf::st_sfc(crs=EPSG_WGS84),
         coord2 = ln %>% sf::st_transform(epsg_code) %>% sf::st_centroid() %>% sf::st_transform(EPSG_WGS84)) 



df.mx <- bind_rows(
  df.mx1 %>% 
    filter(len==1) %>%
    dplyr::select(-ID305B, -source),
  df.mx1 %>% 
    filter(len>1) %>% 
    group_by(id, waterbody1, WATER_NAME) %>% 
    summarise(P=sum(P), jc=mean(jc), len=mean(len)) %>%
    left_join(df.mx2 %>% dplyr::select(id, coord=coord2), by=c("id")))
```
</details>
<br>

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width="60%"}  
df.rv <- sf::st_read("data/gis/Rivers_(2020_Final_WQA_IR_Assessment)/Rivers_(2020_Final_WQA_IR_Assessment).shp", quiet=TRUE) %>%
  mutate(geometry=geometry %>% sf::st_transform(4326)) %>%
  filter(ID305B %in% df.mx1$ID305B)

p <- df.mx %>%
  ggplot() +
  geom_sf(data=vaco1, mapping=aes(geometry=geometry), size=0.2, fill="grey95", color="grey65") +
  geom_sf(data=df.rv, mapping=aes(geometry=geometry), color="#74a9cf", size=0.5) +
  geom_sf(aes(geometry=ln), size=0.2, color="grey20") +
  theme_void()
```

With a couple of exceptions, the strong overlap observed between derived lines (black) and VDEQ lines (blue) indicates that our hypothesis is correct for a vast majority of cases.  Closer inspection reveals a couple of exceptions to this, however since the error introduced from these discrepancies probably won't affect the predictive modeling efforts (and we will probably use the brute-force results anyway), we will accept these errors and move on.

There are `r df.trt %>% filter(!(id %in% df.adj2$id)) %>% nrow()` trout waters that did not yield candidate pairs in the analysis above, which represents `r (100*(df.trt %>% filter(!(id %in% df.adj2$id)) %>% nrow())/(nrow(df.trt))) %>% format(digits=0)`% of the trout waters.  This seems surprisingly large, however a spot-check for "Cook Lake" in Alexandria, VA confirmed that it is, in fact, absent from VDWR data.  Similarly, Thompson WMA Lake is also absent from the VDEQ data.  It is possible that the reason for their absence is that these two lakes are man-made.

<br>


```{r, echo=FALSE, eval=FALSE}
# Try osmdata for geocoding
#d <- lapply(1:nrow(df.mtch), function(i) {
#  s <- paste(df.mtch$nm[i], ", VA",sep="")
#  q <- osmdata::getbb(s) %>% bbox_to_pgon()
#  df <- data.frame(nm=df.mtch$nm[i], osm=q %>% sf::st_sfc() %>% sf::st_set_crs(4326))
#})
#df.mtch3 <- df.mtch2 %>% left_join(do.call(rbind,d), by="nm")
```



## References

<ul>
  <li>MinHash vignette for the `textreuse` package [here](https://cran.r-project.org/web/packages/textreuse/vignettes/textreuse-minhash.html)</li>
  <li>The book chapter from [Mining Massive Datasets](http://infolab.stanford.edu/~ullman/mmds/ch3n.pdf)</li>
  <li>MinHash for dummies [post](http://matthewcasperson.blogspot.com/2013/11/minhash-for-dummies.html)</li>
  <li>A [Medium article](https://towardsdatascience.com/locality-sensitive-hashing-how-to-find-similar-items-in-a-large-set-with-precision-d907c52b05fc) on locality-sensitive hashing</li>
  <li>An [illustrated guide](https://www.pinecone.io/learn/locality-sensitive-hashing/) to LSH</li>
  <li>Comments on using `tokenizers` output with `textreuse` [here](https://github.com/ropensci/textreuse/issues/75)</li>
</ul>
