<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Virginia Trout Water Locations</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Virginia Trout Water Locations</h1>

</div>


<hr>
<p><br></p>
<p>Water bodies that are included in the Virginia Department of Wildlife Recreation (VDWR) trout stocking program can be browsed on an <a href="https://dgif-virginia.maps.arcgis.com/apps/webappviewer/index.html?id=441ed456c8664166bb735b1db6024e48">interactive map</a>, however there doesn’t appear to be a simple way for the average user to download the location data. For this reason, we explore some methods for determining these locations in the sections below.</p>
<p><br></p>
<div id="brute-force-method" class="section level2">
<h2>Brute Force Method</h2>
<p>The no-tech solution to this problem is to simply brute-force our way through the trout water locations by manually searching for each individual location. It’s frustrating to know that the locations are definitely recorded in a database somewhere, just not easily accessible to me personally, so I literally pasted each “trout water” into the search bar on the interactive map, navigated to the appropriate search result, dropped a pin on the location, and copied the relevant coordinates.</p>
<p>As painful as this was, it was manageable (it took about 3-ish hours), and very illuminating. For example, I found a handful of inconsistencies like misspellings, alternative names, or missing waterways. In some cases I resorted to a manual google-maps search to help narrow the field and made a judgement call as to the probable location of some waterway. In all cases I entered a discrete point, even though many of the locations are rivers and streams and trout stocking is probably carried out at a variety of locations along the waterway. In one case I wasn’t able to find the location at all because the name, “Forest Service Office Youth Ponds” was very much ambiguous and I couldn’t find where the Forest Service Office is located (apparently even Google doesn’t know!); in that case I used the center of the respective county.</p>
<p><br></p>
</div>
<div id="vdeq-data" class="section level2">
<h2>VDEQ Data</h2>
<p>The Virginia Department of Environmental Quality (VDEQ) maintains an up-to-date <a href="https://geohub-vadeq.hub.arcgis.com/pages/Water%20Datasets">collection of datasets</a> related to rivers/streams, and lakes/reservoirs, plus a variety of other features. Combining the rivers/streams and lakes/reservoirs data yields 7,135 unique bodies of water, or 4,277 uniquely named bodies of water. What’s the difference? Many of the bodies of water are divided into multiple segments and some are frequently-used names. For example, the James River has 41 sections outlined in the VDEQ data, and Mill Creek has 41. If we look at the geographic distribution of the respective points, the difference becomes clear,</p>
<p><img src="index_files/figure-html/unnamed-chunk-6-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>To a large degree these multiplicity issues can be resolved by filtering the data by county (whereas counties aren’t explicitly listed in the VDEQ data, we derive these from shapes available from the <a href="https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html">Census Bureau</a>). Rivers, however, may require an extra step towards disambiguation. Nevertheless, it’s worth noting that around 75% of the names have only a single entry, so these problems shouldn’t be too pervasive.</p>
<p>Note: after carrying out 90% of this analysis, I discovered that VDEQ has two additional datasets that are specifically labeled as Trout Rivers &amp; Streams and Trout Lakes &amp; Reservoirs. We will revisit these datasets later.</p>
<div id="pairwise-comparisons" class="section level3">
<h3>Pairwise comparisons</h3>
<p>Comparing water bodies between these two datasets is nontrivial. As noted in the section above describing the brute-force approach, there are several cases where misspellings, alternative spellings, ambiguous names, or missing data come into play. Add to this the multiplicities highlighted above for the VDEQ data. With all of this in mind, the strategy here will be to formulate a set of logical rules that will help us come up with a “best guess” as to which trout waters denoted in the VDWR data correspond to which water bodies in the VDEQ data. The initial procedure will look like this,</p>
<ol>
<li>
Filter by county
</li>
<li>
Determine name similarity
</li>
<li>
Filter by jaccard distance
</li>
</ol>
<details>
<p><summary style="font-size:15px">CODE</summary></p>
<pre class="r"><code>#
# Pairwise comparisons
#
t0 &lt;- Sys.time()


d &lt;- lapply(1:nrow(df.trt), function(i) {
  df.deq %&gt;% 
    filter(county == df.trt$county[i]) %&gt;%
    mutate(waterbody1 = df.trt$waterbody1[i],
           jc = stringdist::stringdist(waterbody1, WATER_NAME, method=&quot;jaccard&quot;,q=3),
           id = df.trt$id[i]) %&gt;%
    filter(jc&lt;0.50) %&gt;%
    arrange(id, jc) %&gt;%
    dplyr::select(id, waterbody1, ID305B, WATER_NAME, county, jc, source, coord)
})


df.cnd1 &lt;- do.call(rbind, d)
t1 &lt;- Sys.time()
DT_PR &lt;- t1-t0</code></pre>
</details>
<p><br></p>
<p>The result is a list of candidate pairs that will be used later in the <b>Adjudication</b> step. In the table below, a Jaccard score of zero means the names are identical. Some things worth noting here, which will be discussed in greater depth later, 1) some cases return a single result with exact string match, 2) some cases return multiple results with exact string matches, 3) some cases return a mixture of exact and inexact string matches 4) some cases return only inexact string matches, and 5) some trout waters do not return any candidate pairs. The adjudication step will need to account for each of these scenarios. Some of these scenarios are evident in the sample printed below,</p>
<table class="table lightable-paper" style='width: auto !important; margin-left: auto; margin-right: auto; font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>
<thead>
<tr>
<th style="text-align:left;">
id
</th>
<th style="text-align:left;">
Trout Water
</th>
<th style="text-align:left;">
VDEQ water
</th>
<th style="text-align:right;">
Jaccard
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
trt-001
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-001
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:left;">
Long Spring Run
</td>
<td style="text-align:right;">
0.33
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-005
</td>
<td style="text-align:left;">
German River
</td>
<td style="text-align:left;">
German River
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-006
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-006
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-007
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-007
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-007
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-007
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:left;">
North Fork Holston River
</td>
<td style="text-align:right;">
0.24
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-007
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:left;">
North Fork Holston River
</td>
<td style="text-align:right;">
0.24
</td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
<div id="locality-sensitive-hashing" class="section level3">
<h3>Locality-sensitive hashing</h3>
<p>Locality-sensitive hashing is a technique that can be used to reduce the search space in cases where pairwise comparisons between datasets may become intractable. The methodology, described <a href="http://infolab.stanford.edu/~ullman/mmds/ch3n.pdf">here</a>, takes an approximative approach that mimics the jaccard similarity. The data we are working with here don’t quite meet the threshold of intractability, however it is interesting to go through the mechanics of LSH anyway.</p>
<p>It’s worth noting, however, that LSH is typically discussed within the context of finding similar/duplicate items within a large document corpus, whereas the problem being addressed here is specifically related to the comparison of two different datasets (this may or may not be strictly true; it’s possible that this is a limitation of the specific implementation used here, or it might be related to my own lack of familiarity with the implementation).</p>
<p>The overarching goal here is to use LSH to create a list of candidate pairs. Most of the necessary steps are carried out with the <code>textreuse</code> package, however since the implementation appears to be designed for use with longer documents, we will carry out some pre-processing steps to tokenize text by characters instead of the default, which is by word.</p>
<details>
<p><summary style="font-size:15px">CODE</summary></p>
<pre class="r"><code># Pre-processing: VDEQ data
df.deq2 &lt;- df.deq %&gt;%
  mutate(ngrams     = tokenizers::tokenize_character_shingles(WATER_NAME, n=3,   # tokenize by ngram
                                                              strip_non_alphanum=FALSE,
                                                              simplify=TRUE),  
         len        = purrr::map_int(ngrams, length),                            # number of tokens
         txt_tokens = purrr::map_chr(ngrams, str_c,collapse=&quot; &quot;))                # prep for minhash


# Pre-processing: VDWR data
df.trt2 &lt;- df.trt %&gt;%
  mutate(ngrams     = tokenizers::tokenize_character_shingles(waterbody1, n=3,
                                                          strip_non_alphanum=FALSE,
                                                          simplify=TRUE),
         len        = purrr::map_int(ngrams, length),
         txt_tokens = purrr::map_chr(ngrams, str_c, collapse=&quot; &quot;))</code></pre>
</details>
<p><br></p>
<p>In the present case the water body names are tokenized into ngrams, where n=3. It is useful to take a look at the number of ngrams per name for each dataset,</p>
<p><img src="index_files/figure-html/unnamed-chunk-10-1.png" width="50%" /><img src="index_files/figure-html/unnamed-chunk-10-2.png" width="50%" /> The histograms show an interesting tri-modal feature, most evident in the VDEQ data. Closer inspection reveals that most of the names in the VDEQ data with greater than 30 ngrams follow a pattern like “Unnamed tributary to…”. The peak around 20 mostly consists of more complex names in both datasets, such as those specifying “North Fork..” or “South Fork…”, or something like “Goose Creek/Crooked Run/Gap Run”.</p>
<p>The minhashing workflow here is based largely on the <code>textreuse</code> package <a href="https://cran.r-project.org/web/packages/textreuse/vignettes/textreuse-minhash.html">vignette</a>. We start by generating a minhash function and using that to create a document corpus containing all of the minhashed ngrams. The minhash function converts a collection of tokens into <code>n</code> randomly selected hashes. In the present dataset, there are 799 unique ngrams derived from the trout waters, and 4,804 from the VDEQ water body names. These are mapped to 240 hashes.</p>
<details>
<p><summary style="font-size:15px">CODE</summary></p>
<pre class="r"><code># Create minhash function
minhash &lt;- textreuse::minhash_generator(n=240, seed=1234)</code></pre>
</details>
<p><br></p>
<p>The document corpus is created, which consists of all names from both datasets.</p>
<details>
<p><summary style="font-size:15px">CODE</summary></p>
<pre class="r"><code># Create a named vector of tokens for each row
vec_tokens &lt;- c(df.deq2$txt_tokens, df.trt2$txt_tokens)
names(vec_tokens) &lt;- c(df.deq2$ID305B, df.trt2$id)

# Generate corpus
t0 &lt;- Sys.time()
corpus &lt;- textreuse::TextReuseCorpus(text = vec_tokens, tokenizer = tokenizers::tokenize_ngrams, n = 3,
                          minhash_func = minhash, keep_tokens = TRUE,
                          progress = FALSE, simplify=TRUE)
t1 &lt;- Sys.time()
DT_LS1 &lt;- t1-t0</code></pre>
</details>
<p><br></p>
<p>Locality-sensitive hashing can now be carried out on the corpus. The only remaining parameter is the number of bands to use in the computation. The approximate threshold for jaccard similarity used to create the candidate pairs depends on this value. In the present case <span class="math inline">\(b=40\)</span> is used since it leads to an approximate threshold of around 0.5.</p>
<details>
<p><summary style="font-size:15px">CODE</summary></p>
<pre class="r"><code>t0 &lt;- Sys.time()
buckets_040    &lt;- lsh(corpus, bands = 40, progress = FALSE)
candidates_040 &lt;- lsh_candidates(buckets_040) %&gt;% mutate(bands=40)
t1 &lt;- Sys.time()
DT_LS2 &lt;- t1-t0</code></pre>
</details>
<p><br></p>
<p>The result is a list of candidate pairs, nominally, pairs which will yield a jaccard similarity less than the theshold value implied by the choice of <span class="math inline">\(b\)</span>. With a little bit of post-processing one can generate a result analogous to what was produced above,</p>
<details>
<p><summary style="font-size:15px">CODE</summary></p>
<pre class="r"><code>t0 &lt;- Sys.time()
df.cnd2 &lt;- candidates_040 %&gt;%
  filter(a %in% df.trt2$id) %&gt;%
  rename(id=a, ID305B=b) %&gt;%
  left_join(df.trt %&gt;% dplyr::select(id, waterbody1, county), by=c(&quot;id&quot;)) %&gt;%
  left_join(df.deq %&gt;% dplyr::select(ID305B, WATER_NAME, source, coord, county2=county), by=c(&quot;ID305B&quot;)) %&gt;%
  filter(county==county2) %&gt;%
  mutate(jc = stringdist::stringdist(waterbody1, WATER_NAME, method=&quot;jaccard&quot;,q=3)) %&gt;%
  arrange(id, jc) %&gt;%
  dplyr::select(id, waterbody1, ID305B, WATER_NAME, county, jc, source, coord)
t1 &lt;- Sys.time()
DT_LS3 &lt;- t1-t0
DT_LS &lt;- DT_LS1 + DT_LS2 + DT_LS3</code></pre>
</details>
<p><br></p>
<table class="table lightable-paper" style='width: auto !important; margin-left: auto; margin-right: auto; font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>
<thead>
<tr>
<th style="text-align:left;">
id
</th>
<th style="text-align:left;">
Trout Water
</th>
<th style="text-align:left;">
VDEQ water
</th>
<th style="text-align:right;">
Jaccard
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
trt-001
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-001
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:left;">
Long Spring Run
</td>
<td style="text-align:right;">
0.33
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-003
</td>
<td style="text-align:left;">
Slate Lick Lake
</td>
<td style="text-align:left;">
Slate Lick Branch
</td>
<td style="text-align:right;">
0.53
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-003
</td>
<td style="text-align:left;">
Slate Lick Lake
</td>
<td style="text-align:left;">
Slate Lick Branch
</td>
<td style="text-align:right;">
0.53
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-004
</td>
<td style="text-align:left;">
Slate Lick Run
</td>
<td style="text-align:left;">
Slate Lick Branch
</td>
<td style="text-align:right;">
0.50
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-004
</td>
<td style="text-align:left;">
Slate Lick Run
</td>
<td style="text-align:left;">
Slate Lick Branch
</td>
<td style="text-align:right;">
0.50
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-004
</td>
<td style="text-align:left;">
Slate Lick Run
</td>
<td style="text-align:left;">
Spruce Lick Run
</td>
<td style="text-align:right;">
0.53
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-005
</td>
<td style="text-align:left;">
German River
</td>
<td style="text-align:left;">
German River
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-006
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-006
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
</tbody>
</table>
</div>
<div id="comparison-of-pairwise-and-lsh-methods" class="section level3">
<h3>Comparison of Pairwise and LSH methods</h3>
<p>In principle, the <em>Pairwise</em> and <em>LSH</em> methods outlined above do more or less the same thing, so it is interesting to do a quick comparison of the results.</p>
<p>First, ignoring some of the pre-processing steps, the Pairwise method took about <b>3 s</b> to run, whereas the LSH method took around <b>30 s</b> to generate the corpus (6s), compute locality-sensitive hashes (21s), and carry out some light post-processing (0.2s). Note that this not a completely fair comparison, and there may be more optimization to be carried out. For example, the pairwise method doesn’t compare all records with all other records; instead it compares each record from the trout data to all records in the VDEQ data <em>that are in the same county</em>. In effect, we are carrying out a blocking process prior to the comparing the datasets. In the LSH method detailed above this blocking step is carried out as part of the post-processing. Not only that, but the corpus doesn’t distinguish between datasets, so the LSH method is intrinsically comparing each record with all other records <em>in both datasets</em>.</p>
<p>Next, it is worth comparing the output of each method,</p>
<p><img src="index_files/figure-html/unnamed-chunk-18-1.png" width="48%" /><img src="index_files/figure-html/unnamed-chunk-18-2.png" width="48%" /></p>
<p>Notice that the Jaccard similarity shows a sharp cutoff at 0.5 for the Pairwise method, but the boundary is fuzzier with LSH. This is a consequence of the latter being an approximate method. It may be possible to refine the LSH parameters in a way so as to create a sharper cutoff. Also, the distribution of similarity scores is different for the two methods as the value becomes larger, however the number of exact matches is identical. This has to do with the probabilistic nature of LSH.</p>
<p><br></p>
</div>
<div id="adjudication" class="section level3">
<h3>Adjudication</h3>
<p>The candidate pairs identified above ideally represent the same waterways present in both datasets, however the reality is more complicated and nuanced. For example, as was briefly mentioned above, there are five possible outcomes for each candidate pair,</p>
<ol>
<li>
Single exact match
</li>
<li>
Multiple exact matches
</li>
<li>
Mixture of exact and inexact matches
</li>
<li>
Inexact matches
</li>
<li>
No candidates
</li>
</ol>
<p>During the adjudication process the goal will be to assign a likelihood value to each proposed candidate pair. To do this, we will use Bayes Law,</p>
<p><span class="math display">\[
Pr(\theta | y) = \frac{Pr(y | \theta) Pr(\theta)}{Pr(y)}
\]</span> where,</p>
<ul>
<li>
<span class="math inline">\(Pr(\theta | y)\)</span> is the probability that the candidate pair is correct, given similarity score <span class="math inline">\(y\)</span>
</li>
<li>
<span class="math inline">\(Pr(y | \theta)\)</span> is the probability of similarity score <span class="math inline">\(y\)</span>, given the candidate pair is correct
</li>
<li>
<span class="math inline">\(Pr(\theta)\)</span> is the prior probability, or the probability that the candidate pair is correct
</li>
<li>
<span class="math inline">\(Pr(y)\)</span> is the probability of similarity score <span class="math inline">\(y\)</span>
</li>
</ul>
<p>The value for <span class="math inline">\(Pr(y | \theta)\)</span> would nominally be determined from data. For example, if a subset of the candidate pairs were adjudicated manually or otherwise known <em>a priori</em>, this information could be used to derive an expression for the probability of similarity score <span class="math inline">\(y\)</span>, given a correct candidate pair. Technically, this information is available in the present case since the brute-force method was carried out above. However, this is not a typical scenario, so we will use this as a comparative method only. If no information is available then we will need to come up with a “best guess” as to the relationship. With this in mind, we assume that the likelihood drops off exponentially as a function of the similarity score, with the probability at <span class="math inline">\(sim=0.1\)</span> exactly half that of <span class="math inline">\(sim=0.0\)</span>, and <span class="math inline">\(sim=0.2\)</span> half that of <span class="math inline">\(sim=0.1\)</span>, and so on. In other words, we assume the relation, <span class="math inline">\(P = e^{-\lambda x}\)</span>, where <span class="math inline">\(\lambda = \frac{ln(2)}{t_{1/2}}\)</span> and <span class="math inline">\(t_{1/2} = 0.1\)</span>,</p>
<p><img src="index_files/figure-html/unnamed-chunk-19-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>The value for <span class="math inline">\(Pr(\theta)\)</span> is the prior probability that the candidate pair is correct. This depends on the number of candidate pairs, plus the possibility that <em>none</em> of the candidate pairs are correct. Assuming a uniform distribution, we use <span class="math inline">\(\frac{1}{n+1}\)</span>, where <span class="math inline">\(n\)</span> is the number of candidate pairs.</p>
<p>The normalization factor can be expanded to,</p>
<p><span class="math display">\[
Pr(y) = \sum_{\theta}{Pr(\theta) Pr(y | \theta)}
\]</span> This will be evaluated for each candidate pair determined for a given trout water, plus the possibility that none of the candidates are correct. Since there is no information as to the probability that none of the candidate pairs is correct, we are forced to come up with a “best guess”. Considering that the VDEQ dataset is supposed to be comprehensive, the likelihood that a given trout waterway is not present is likely very small. However, there is also the possibility that the waterway is present, but the name is sufficiently different that it is not offered as a candidate pair. Given these factors, we estimate that there is a 2% likelihood that the waterway is not represented as a candidate pair.</p>
<details>
<p><summary style="font-size:15px">CODE</summary></p>
<pre class="r"><code>faker_frame &lt;- function(n) {
  data.frame(WATER_NAME = &quot;None&quot;,
             P_cn = 0.02,
             P_pr = 1/(n+1))
}

bsn &lt;- function(df) {
  df %&gt;%
    mutate(P_cn = fctn(jc),
           P_pr = 1/(nrow(df)+1)) %&gt;%
    bind_rows(faker_frame(nrow(df))) %&gt;%
    mutate(P_yy = sum(P_cn*P_pr),
           P = P_cn*P_pr/P_yy)
}

df.adj1 &lt;- df.cnd1 %&gt;% 
  tidyr::nest(data=c(ID305B, WATER_NAME, source,coord, jc)) %&gt;%
  mutate(data = purrr::map(data,bsn)) %&gt;%
  tidyr::unnest(cols=c(data))

df.adj2 &lt;- df.cnd2 %&gt;% 
  tidyr::nest(data=c(ID305B, WATER_NAME, source,coord, jc)) %&gt;%
  mutate(data = purrr::map(data,bsn)) %&gt;%
  tidyr::unnest(cols=c(data))</code></pre>
</details>
<p><br></p>
<p>Combining all of this into Bayes Law gives normalized probability values for each candidate pair, plus an additional option that none are correct. A sample of the results is listed in the table below. Note that the probability sums to 1.0 for each trout water, although in some cases this appears not to be the case due to rounding carried out for display purposes.</p>
<table class="table lightable-paper" style='width: auto !important; margin-left: auto; margin-right: auto; font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>
<thead>
<tr>
<th style="text-align:left;">
id
</th>
<th style="text-align:left;">
Trout Water
</th>
<th style="text-align:left;">
VDEQ water
</th>
<th style="text-align:right;">
Jaccard
</th>
<th style="text-align:right;">
Probability
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
trt-001
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.89
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-001
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:left;">
Long Spring Run
</td>
<td style="text-align:right;">
0.33
</td>
<td style="text-align:right;">
0.09
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-001
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:left;">
None
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
0.02
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-005
</td>
<td style="text-align:left;">
German River
</td>
<td style="text-align:left;">
German River
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.98
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-005
</td>
<td style="text-align:left;">
German River
</td>
<td style="text-align:left;">
None
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
0.02
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-006
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.50
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-006
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.50
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-006
</td>
<td style="text-align:left;">
Irish Creek
</td>
<td style="text-align:left;">
None
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
0.01
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-007
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.23
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-007
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:left;">
South Fork Holston River
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.23
</td>
</tr>
</tbody>
</table>
<p>A close inspection of the sample results listed in the table above doesn’t reveal anything overly surprising. For example, in the case of “Irish Creek” there were two exact string matches and each are assigned approximately a 50% chance of being correct, with a very small probability that none are correct. The results for “South Fork Holston River” are truncated in the table above, but there were 13 candidate pairs, 3 of which are exact string matches. The model gives a 68% chance that one of these exact matches are correct, and a 32% chance that one of the ten other candidate pairs are correct (plus a tiny chance that none are correct).</p>
<p><br></p>
<div id="dealing-with-multiplicity" class="section level4">
<h4>Dealing with multiplicity</h4>
<p>In cases where a single trout water yielded two or more string matches with exactly the same name, it is useful to take a step back and consider that this likely are, in fact, the same waterways. Recall the example above where the James River extended most of the way across the state, but it was divided into 41 individual segments. Given this, we can deal with the multiplicity problem by simply merging these data together. One way to check if this is reasonable is to aggregate by waterway, connect the dots between the candidate pairs, and compare with the waterway lines included in the original Rivers/Streams dataset,</p>
<details>
<p><summary style="font-size:15px">CODE</summary></p>
<pre class="r"><code># filter to just max prob
maxonly &lt;- function(df) {df %&gt;% filter(P == max(P))}
make_line &lt;- function(lonlat) { lonlat %&gt;% as.matrix() %&gt;% sf::st_linestring() }


df.mx1 &lt;- df.adj1 %&gt;%
  dplyr::select(id, waterbody1,ID305B, WATER_NAME, source,coord, jc,P) %&gt;%
  tidyr::nest(data=c(ID305B, WATER_NAME, source,coord, jc,P)) %&gt;%
  mutate(data = purrr::map(data, maxonly),
         len  = purrr::map_int(data,nrow)) %&gt;%
  tidyr::unnest(cols=c(data)) 

df.mx2 &lt;- df.mx1 %&gt;%
  filter(len&gt;1) %&gt;%
  group_by(id) %&gt;%
  summarise(m = sf::st_coordinates(coord)) %&gt;% 
  arrange(id,m) %&gt;%
  tidyr::nest() %&gt;%              
  mutate(ln = purrr::map(data, make_line) %&gt;% sf::st_sfc(crs=EPSG_WGS84),
         coord2 = ln %&gt;% sf::st_transform(epsg_code) %&gt;% sf::st_centroid() %&gt;% sf::st_transform(EPSG_WGS84)) 



df.mx &lt;- bind_rows(
  df.mx1 %&gt;% 
    filter(len==1) %&gt;%
    dplyr::select(-ID305B, -source),
  df.mx1 %&gt;% 
    filter(len&gt;1) %&gt;% 
    group_by(id, waterbody1, WATER_NAME) %&gt;% 
    summarise(P=sum(P), jc=mean(jc), len=mean(len)) %&gt;%
    left_join(df.mx2 %&gt;% dplyr::select(id, coord=coord2), by=c(&quot;id&quot;)))</code></pre>
</details>
<p><br></p>
<p><img src="index_files/figure-html/unnamed-chunk-23-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>With a few exceptions, the derived lines (black) more or less trace along the VDEQ (blue) waterways (in the original dataset these are represented as lines). This implies that we can, in fact, combine identically-named waterways from the data.</p>
<table class="table lightable-paper" style='width: auto !important; margin-left: auto; margin-right: auto; font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>
<thead>
<tr>
<th style="text-align:left;">
id
</th>
<th style="text-align:left;">
Trout Water
</th>
<th style="text-align:left;">
VDEQ Water
</th>
<th style="text-align:right;">
Probability
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
trt-001
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:left;">
Spring Run
</td>
<td style="text-align:right;">
0.89
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-005
</td>
<td style="text-align:left;">
German River
</td>
<td style="text-align:left;">
German River
</td>
<td style="text-align:right;">
0.98
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-013
</td>
<td style="text-align:left;">
Upper Passage Creek
</td>
<td style="text-align:left;">
Passage Creek
</td>
<td style="text-align:right;">
0.81
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-020
</td>
<td style="text-align:left;">
Big Wilson Creek
</td>
<td style="text-align:left;">
Big Wilson Creek
</td>
<td style="text-align:right;">
0.66
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-027
</td>
<td style="text-align:left;">
Wilson Creek
</td>
<td style="text-align:left;">
Wilson Creek Upper
</td>
<td style="text-align:right;">
0.35
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-029
</td>
<td style="text-align:left;">
Peters Mill Creek
</td>
<td style="text-align:left;">
Peters Mill Run
</td>
<td style="text-align:right;">
0.21
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-035
</td>
<td style="text-align:left;">
McFalls Creek
</td>
<td style="text-align:left;">
McFalls Creek
</td>
<td style="text-align:right;">
0.98
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-036
</td>
<td style="text-align:left;">
Falls Hollow
</td>
<td style="text-align:left;">
Falls Hollow
</td>
<td style="text-align:right;">
0.98
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-040
</td>
<td style="text-align:left;">
Sugar Hollow Reservoir
</td>
<td style="text-align:left;">
Sugar Hollow Reservoir
</td>
<td style="text-align:right;">
0.98
</td>
</tr>
<tr>
<td style="text-align:left;">
trt-041
</td>
<td style="text-align:left;">
Douthat Lake
</td>
<td style="text-align:left;">
Douthat Lake
</td>
<td style="text-align:right;">
0.98
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p><b>TODO: Compare results with “known” locations.</b></p>
</div>
</div>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<ul>
<li>
MinHash vignette for the <code>textreuse</code> package <a href="https://cran.r-project.org/web/packages/textreuse/vignettes/textreuse-minhash.html">here</a>
</li>
<li>
The book chapter from <a href="http://infolab.stanford.edu/~ullman/mmds/ch3n.pdf">Mining Massive Datasets</a>
</li>
<li>
MinHash for dummies <a href="http://matthewcasperson.blogspot.com/2013/11/minhash-for-dummies.html">post</a>
</li>
<li>
A <a href="https://towardsdatascience.com/locality-sensitive-hashing-how-to-find-similar-items-in-a-large-set-with-precision-d907c52b05fc">Medium article</a> on locality-sensitive hashing
</li>
<li>
An <a href="https://www.pinecone.io/learn/locality-sensitive-hashing/">illustrated guide</a> to LSH
</li>
<li>
Comments on using <code>tokenizers</code> output with <code>textreuse</code> <a href="https://github.com/ropensci/textreuse/issues/75">here</a>
</li>
</ul>
<br>
<hr>
<p><br></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
